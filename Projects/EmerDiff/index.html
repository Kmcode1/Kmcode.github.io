<!DOCTYPE html>
<html>
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DYTHLW1X9V"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DYTHLW1X9V');
</script>

  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="We present EmerDiff, an unsupervised image segmentor solely built on the semantic knowledge extracted from a pre-trained diffusion model.">
  <meta property="og:title" content="EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models"/>
  <meta property="og:description" content="We present EmerDiff, an unsupervised image segmentor solely built on the semantic knowledge extracted from a pre-trained diffusion model."/>
  <meta property="og:url" content="Kmcode1.github.io/Projects/EmerDiff/index.html"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!--<meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>!-->


  <meta name="twitter:title" content="EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models">
  <meta name="twitter:description" content="We present EmerDiff, an unsupervised image segmentor solely built on the semantic knowledge extracted from a pre-trained diffusion model.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!--<meta name="twitter:image" content="static/images/your_twitter_banner_image.png">!-->
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Diffusion models, Unsupervised learning, Representation learning, Unsupervised segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://kmcode1.github.io/" target="_blank">Koichi Namekata</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href=""> Amirmojtaba Sabour</a><sup>1,2</sup>,</span>
                  <span class="author-block">
                    <a href="http://www.cs.toronto.edu/~fidler/" target="_blank">Sanja Fidler</a><sup>1,2,3</sup>,
                  </span>
<span class="author-block">
                    <a href="https://seung-kim.github.io/seungkim/" target="_blank">Seung Wook Kim</a><sup>1,2,3</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>University of Toronto, <sup>2</sup>Vector Institute, <sup>3</sup>NVIDIA<br>ICLR, 2024</span>
                    <span class="eql-cntrb"><small></span>
                  </div>

                  

                  <!-- Github link -->
                  <!--<span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>!-->

		<div class="column has-text-centered">
                    <div class="publication-links">
                         
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv(TBA)</span>
                </a>
              </span>

	      <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://openreview.net/forum?id=YqyTXmF8Y2" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                </span>
	      
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video> !-->
      <img src="static/images/teaser.jpeg">
      <h2 class="subtitle has-text-centered">
        EmerDiff is an unsupervised image segmentor solely built on the semantic knowledge extracted from a pre-trained diffusion model. The obtained fine-detailed segmentation maps suggest the presence of highly accurate pixel-level semantic knowledge in diffusion models. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Diffusion models have recently received increasing research attention for their remarkable transfer abilities in semantic segmentation tasks. 
However, generating fine-grained segmentation masks with diffusion models often requires additional training on annotated datasets, leaving it unclear to what extent pre-trained diffusion models alone understand the semantic relations of their generated images. To address this question, we leverage the semantic knowledge extracted from Stable Diffusion (SD) and aim to develop an image segmentor capable of generating fine-grained segmentation maps without any additional training. The primary difficulty stems from the fact that semantically meaningful feature maps typically exist only in the spatially lower-dimensional layers, which poses a challenge in directly extracting pixel-level semantic relations from these feature maps. To overcome this issue, our framework identifies semantic correspondences between image pixels and spatial locations of low-dimensional feature maps by exploiting SD's generation process and utilizes them for constructing image-resolution segmentation maps. In extensive experiments, the produced segmentation maps are demonstrated to be well delineated and capture detailed parts of the images, indicating the existence of highly accurate pixel-level semantic knowledge in diffusion models. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="hero is-small">
  <div class = "container is-max-desktop">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Key observation</h2>
      <div class="level-set has-text-justified">
            <p>
              We begin by investigating how a local change in the values of low-resolution feature maps (e.g. 16×16) influences the pixel values of the generated images (e.g. 512×512). We discover that when we perturb the values of a sub-region of low-resolution feature maps (middle row of the figure below), the generated images are altered in a way that only the pixels semantically related to that sub-region are changed notably (bottom row of the figure). <br><br>
            </p>
      </div>
      <img src="static/images/modulation.jpg" alt="Baselines vs. RGB" class="center-image">
      <h3>
          <b> Observation. </b> First row: original image. Second row: local change in low-resolution feature maps (e.g. 16×16). Third row: resultant change in final generated images (e.g. 512×512).
      </h3><br>
      Following the above observation, we can automatically identify the semantic correspondences between image pixels and a sub-region of
low-dimensional feature maps by simply measuring the change in the pixel values.
      </div>
  </div>
</div>
</div>
</div>
</section>

<section class="hero is-small">
  <div class = "container is-max-desktop">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Pipeline</h2>
      EmerDiff generates fine-grained segmentation maps in an unsupervised manner. First, we generate low-resolution segmentation maps (e.g. 16×16) by applying k-means on the low-dimensional feature maps (green part of the figure below). Then, we build image-resolution segmentation maps (e.g. 512×512) in a top-down manner by mapping each image pixel to the most semantically corresponding low-resolution mask (orange part of the figure). These semantic correspondences are extracted from the diffusion models via Modulated Denoising Process leveraging the above observation (red part). <br><br>
      <img src="static/images/method.jpg" alt="unsupervised results"/>
      </div>
  </div>
</div>
</div>
</div>
</section>

<section class="hero is-small">
  <div class = "container is-max-desktop">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Results</h2>
      <img src="static/images/naive_comparison_.jpg" alt="naive comparison"/>
        <b>Qualitative comparison with naively upsampled low-resolution segmentation maps.</b> Our segmentation maps are fine-grained and precisely capture detailed parts of the objects.<br><br>
      <img src="static/images/mask_ablation.jpg" alt="unsupervised results"/>
        <b>Varying the number of segmentation masks.</b> Our framework consistently groups objects in a semantically meaningful manner.
      </div>
  </div>
</div>
</div>
</div>
</section>

<section class="hero is-small">
  <div class = "container is-max-desktop">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Unsupervised semantic segmentation</h2>
      Here we apply EmerDiff to unsupervised semantic segmentation. For more analysis, please refer to the paper.<br><br>
      <img src="static/images/result.jpg" alt="unsupervised results"/>
      <!--<h2 class="subtitle has-text-centered">
          Visualization of unsupervised semantic segmentation.
        </h2>!-->
      </div>
  </div>
</div>
</div>
</div>
</section>
<!-- End image carousel -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>tba</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
